{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dee17a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.tavily_search import TavilySearchResults \n",
    "from langchain.agents import tool\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.runnables.graph_mermaid import MermaidDrawMethod\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddc54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa368441",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults(api_key =TAVILY_API_KEY)\n",
    "\n",
    "@tool\n",
    "\n",
    "def research_agent(input_query: str) -> str:\n",
    "    \"\"\"Uses Tavily To get the search results for a query .\"\"\"\n",
    "    search_results =tavily_tool.run(input_query,num_results=5)\n",
    "    print(f\"Reseach Results : {search_results}\")\n",
    "    return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ce2d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY,temperature=0.7)\n",
    "\n",
    "def answer_drafter(research_output: str) -> str:\n",
    "    print(f\"Drafting the answer ...\")\n",
    "    prompt = f\"\"\" you are an expert researcher .\n",
    "    use the following search results to answer the question in a clear and detailed way .\n",
    "\n",
    "    Search Results:\n",
    "    {research_output}\n",
    "\n",
    "Write a well structured Answer:\n",
    "\n",
    "\"\"\" \n",
    "    Drafted_answer=llm.invoke(prompt).content \n",
    "    print(f\"Drafted_answer: {Drafted_answer}\")\n",
    "    return Drafted_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6bcc960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91832\\AppData\\Local\\Temp\\ipykernel_5300\\543328916.py:2: LangGraphDeprecationWarning: Initializing StateGraph without state_schema is deprecated. Please pass in an explicit state_schema instead of just an input and output schema.\n",
      "  workflow = StateGraph(input=\"input_query\", output=\"final_answer\")\n",
      "c:\\Users\\91832\\Desktop\\Tavily_web\\tavily\\lib\\site-packages\\langgraph\\graph\\state.py:89: UserWarning: Invalid state_schema: input_query. Expected a type or Annotated[type, reducer]. Please provide a valid schema to ensure correct updates.\n",
      " See: https://langchain-ai.github.io/langgraph/reference/graphs/#stategraph\n",
      "  warnings.warn(\n",
      "c:\\Users\\91832\\Desktop\\Tavily_web\\tavily\\lib\\site-packages\\langgraph\\graph\\state.py:89: UserWarning: Invalid state_schema: final_answer. Expected a type or Annotated[type, reducer]. Please provide a valid schema to ensure correct updates.\n",
      " See: https://langchain-ai.github.io/langgraph/reference/graphs/#stategraph\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Defining the Langgraph work Flow\n",
    "workflow = StateGraph(input=\"input_query\", output=\"final_answer\")\n",
    "\n",
    "\n",
    "# adding the two agents workflow \n",
    "workflow.add_node(\"research\", RunnableLambda(research_agent))\n",
    "workflow.add_node(\"draft\",RunnableLambda(answer_drafter))\n",
    "\n",
    "# seting  up the flow \n",
    "\n",
    "workflow.set_entry_point(\"research\")\n",
    "workflow.add_edge(\"research\",\"draft\")\n",
    "workflow.set_finish_point(\"draft\")\n",
    "\n",
    "\n",
    "# compile the graph \n",
    "\n",
    "graph_app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f116e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseach Results : [{'title': 'What is langchain? - Reddit', 'url': 'https://www.reddit.com/r/LangChain/comments/13895ru/what_is_langchain/', 'content': 'LangChain. LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production.', 'score': 0.9341134}, {'title': 'What Is LangChain? - IBM', 'url': 'https://www.ibm.com/think/topics/langchain', 'content': 'What Is LangChain? | IBM\\nMy IBM Log in Subscribe   \\nWhat is LangChain?\\nArtificial Intelligence\\n31 October 2023\\nLink copied\\nWhat is LangChain?\\nLangChain is an open source orchestration framework for the development of applications using large language models (LLMs). Available in both Python- and Javascript-based libraries, LangChain‚Äôs tools and APIs simplify the process of building LLM-driven applications like chatbots and virtual agents. [...] LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models. These modular components‚Äîlike functions and object classes‚Äîserve as the building blocks of generative AI programs. They can be ‚Äúchained‚Äù together to create applications, minimizing the amount of code and fine understanding required to execute complex NLP tasks. Though LangChain‚Äôs abstracted approach may limit the extent to which an expert [...] The latest AI News + Insights\\nDiscover expertly curated insights and news on AI, cloud and more in the weekly Think Newsletter.\\nSubscribe today\\nHow does LangChain work?\\nAt LangChain‚Äôs core is a development environment that streamlines the programming of LLM applications through the use of\\xa0abstraction: the simplification of code by representing one or more complex processes as a named component that encapsulates all of its constituent steps.', 'score': 0.9317675}, {'title': 'LangChain - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': \"License MIT License\\nWebsite LangChain.com\\nLangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\", 'score': 0.9294982}, {'title': 'Introduction | ü¶ú LangChain', 'url': 'https://python.langchain.com/docs/introduction/', 'content': 'Introduction\\nLangChain is a framework for developing applications powered by large language models (LLMs).\\nLangChain simplifies every stage of the LLM application lifecycle:', 'score': 0.9159971}, {'title': 'What is LangChain? - AWS', 'url': 'https://aws.amazon.com/what-is/langchain/', 'content': 'LangChain is an open source framework for building applications based on large language models (LLMs). LLMs are large deep-learning models pre-trained on large amounts of data that can generate responses to user queries‚Äîfor example, answering questions or creating images from text-based prompts. LangChain provides tools and abstractions to improve the customization, accuracy, and relevancy of the information the models generate. For example, developers can use LangChain components to build new [...] What are the core components of LangChain?\\nUsing LangChain, software teams can build context-aware language model systems with the following modules.\\nLLM interface\\nLangChain provides APIs with which developers can connect and query LLMs from their code. Developers can interface with public and proprietary models like GPT, Bard, and PaLM with LangChain by making simple API calls instead of writing complex code.\\nPrompt templates [...] Using Amazon Bedrock, Amazon Kendra, Amazon SageMaker JumpStart, LangChain, and your LLMs, you can build highly-accurate generative artificial intelligence (generative AI) applications on enterprise data. LangChain is the interface that ties these components together:', 'score': 0.9092728}]\n",
      "Drafting the answer ...\n",
      "Drafted_answer: LangChain is an open-source framework and developer toolkit that helps developers create applications using large language models (LLMs). It simplifies the process of building LLM-driven applications such as chatbots and virtual agents by providing tools and APIs that streamline the development process. LangChain is available in both Python- and Javascript-based libraries, allowing developers to leverage its modular components to create generative AI programs.\n",
      "\n",
      "At the core of LangChain is a development environment that utilizes abstraction to simplify the programming of LLM applications. Abstraction involves representing complex processes as named components that encapsulate all their constituent steps, making it easier for developers to work with language models.\n",
      "\n",
      "LangChain's use cases include document analysis and summarization, chatbots, and code analysis. By providing APIs for connecting and querying LLMs from code, LangChain allows developers to interface with public and proprietary models like GPT, Bard, and PaLM with simple API calls instead of writing complex code.\n",
      "\n",
      "Overall, LangChain serves as a valuable framework for software teams looking to build context-aware language model systems and create highly accurate generative artificial intelligence applications. It provides the necessary components and abstractions to improve customization, accuracy, and relevancy in the information generated by language models.\n",
      "Final Answer :\n",
      "LangChain is an open-source framework and developer toolkit that helps developers create applications using large language models (LLMs). It simplifies the process of building LLM-driven applications such as chatbots and virtual agents by providing tools and APIs that streamline the development process. LangChain is available in both Python- and Javascript-based libraries, allowing developers to leverage its modular components to create generative AI programs.\n",
      "\n",
      "At the core of LangChain is a development environment that utilizes abstraction to simplify the programming of LLM applications. Abstraction involves representing complex processes as named components that encapsulate all their constituent steps, making it easier for developers to work with language models.\n",
      "\n",
      "LangChain's use cases include document analysis and summarization, chatbots, and code analysis. By providing APIs for connecting and querying LLMs from code, LangChain allows developers to interface with public and proprietary models like GPT, Bard, and PaLM with simple API calls instead of writing complex code.\n",
      "\n",
      "Overall, LangChain serves as a valuable framework for software teams looking to build context-aware language model systems and create highly accurate generative artificial intelligence applications. It provides the necessary components and abstractions to improve customization, accuracy, and relevancy in the information generated by language models.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is langchain and what are the importance of it and how it is different to others  ?\"\n",
    "\n",
    "results = graph_app.invoke({'input_query':query})\n",
    "\n",
    "#print the final results\n",
    "\n",
    "print(\"Final Answer :\")\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tavily",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
